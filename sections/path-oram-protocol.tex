% cSpell:ignore mybox

\section{Path ORAM protocol}

	\subsection{Overview}

		\begin{frame}{Diagram}
			
			\input{diagrams/protocol}

			\note<1> {
				Here is the diagram of PathORAM protocol.
				There are two components in the ORAM model and a user interacting with the system.
				
				Server basically holds a binary tree of buckets with encrypted blocks.

				Client holds two data structures --- position map and stash --- we will talk about them in a moment.
			}

			\note<2>{
				First, user makes a request to the (trusted) client part.
				User requests --- to read or to write --- a block with certain identifier.
			}

			\note<3,4>{
				If client does not have the block in stash, it makes a request to the server and reads a path with encrypted blocks.

				Server responds with a path of buckets of encrypted blocks.
			}

			\note<5>{
				Client manipulates these blocks --- re-encrypts them, shuffles them and write the path back.
				We will talk about how client writes path back in a randomized way.
			}

			\note<6>{
				Finally, a client returns data to the user.
			}

		\end{frame}

		\begin{frame}{Main invariant}
			
			The client stores a small amount of local data in a \textbf{stash}.
			The server-side storage is treated as a \textbf{binary tree} where each node is a \textbf{bucket} that holds an exact fixed number of \textbf{blocks}.

			\begin{block}{Invariant}
				At any time, each block is mapped to a uniformly random leaf bucket in the tree, and unstashed blocks are always placed in some bucket along the path to the mapped leaf.
			\end{block}

			\note{
				An underlying data structure for PathORAM is a binary tree.
				Client has a position table where each data block ID is mapped to the leaf node.
				Each time access occurs, whole path from the leaf to the root gets read and written.
				This ensures indistinguishability.

				The goal of the invariant is to keep position map accurate at all times.
			}
		\end{frame}

	\subsection{Server storage}

		\begin{frame}{\subsecname}
			
			\begin{block}{Binary tree}
				The server stores a binary tree data structure of height $L$ and $2^L$ leaves.
				We then need $L = \ceil*{ \log_2 N }$ levels. 
				The levels of the tree are numbered $0$ to $L$ where level $0$ denotes the root of the tree and level $L$ denotes the leaves.
			\end{block}

			\note{
				Let us define $L$ --- the height of our tree.
				Then reasonably it will be equal to $\log_2 N$ rounded up.
				Let us also define 0 level as root and $L_\text{th}$ level as leaves.
			}
		\end{frame}

		\begin{frame}{\subsecname}
			
			\begin{block}{Bucket}
				Each node in the tree is called \textbf{bucket}. 
				Each bucket can contain up to $Z$ real blocks. 
				If a bucket has fewer than $Z$ real blocks, it is padded with dummy blocks to always be of size $Z$.
			\end{block}

			\note{
				Each node in a tree is a bucket that contains $Z$ blocks.
				For the sake of indistinguishability, we pad bucket with dummy encrypted blocks.
				Choice of $Z$ is a parameter.
				Experimental results show that small constant, eq.\ 4, will suffice.
			}
		\end{frame}

		\begin{frame}{\subsecname}
			
			\begin{block}{Path}
				Let $x \in \{ 0, 1, \ldots, 2^L - 1 \}$ denote the $x_{\text{th}}$ leaf node in the tree. 
				Any leaf node $x$ defines a unique path from the root of the tree to the leaf $x$.
				We use $\mathcal{P}(x)$ to denote a set of buckets along the path from leaf $x$ to the root. 
				Additionally, $\mathcal{P}(x,l)$ denotes the bucket in $\mathcal{P}(x)$ at level $l$ in the tree.
			\end{block}

			\note{
				Let us define a path from leaf $x$ to the root as $\mathcal{P}(x)$.
				Let us also define $\mathcal{P}(x,l)$ as the bucket along the path at level $l$.
			}
		\end{frame}

		\begin{frame}{\subsecname}
			
			\begin{block}{Server storage size}
				Total server storage used is about $Z \cdot N$ blocks.
				Since $Z$ is a small constant, server storage is $\BigO{N}$.
			\end{block} 

			\note{
				Let us make an important observation.
				The total server storage used is the order of $N$ since $Z$ is a small constant.
			}
		\end{frame}

	\subsection{Client storage}

		\begin{frame}{\subsecname}
			
			\begin{block}{Stash}
				The client locally stores overflowing blocks in a local data structure $S$ called \textbf{stash}.
				The stash has a worst-case size of $\BigO{\log N} \cdot \omega (1)$ blocks with high probability.
				The stash is usually empty after each ORAM read/write operation completes.
			\end{block} 

			\note{
				The core component of the client is stash.
				It is a local data structure that stores overflowing blocks.
				PathORAM protocol is randomized, and the error is the event that this stash overflows.
				The analysis, though, shows that for $\log N$ size of the stash this happens with negligible probability.
			}
		\end{frame}

		\begin{frame}{\subsecname}
			
			\begin{block}{Position map}
				The client stores a position map, such that $x := \text{position}[a]$ means that block $a$ is currently mapped to the $x_\text{th}$ leaf node --- this means that block $a$ resides in some bucket in path $\mathcal{P}(x)$, or in the stash. 
				The position map changes over time as blocks are accessed and remapped.
			\end{block} 

			\note{
				Another core structure of the client is the position table.
				It is a simple lookup table that maps the block with identifier $a$ to some leaf $x$.
				The bucket does not necessarily live in the leaf, but it is guaranteed to live somewhere along the path or in the stash.
				The key to security is the re-randomization of this table on each access.
			}
		\end{frame}

		\begin{frame}{\subsecname}
			
			\begin{block}{Bandwidth}
				For each load or store operation, the client reads a path of $Z \log N$ blocks from the server and then writes it back, resulting in a total of $2Z \log N$ blocks bandwidth used per access. 
				Since $Z$ is a constant, the bandwidth usage is $\BigO{\log N}$ blocks.
			\end{block} 

			\note{
				Each read and write, client reads the whole path and writes it back.
				A path is $Z \log N$ blocks, and since $Z$ is a small constant, resulting usage is $\BigO{\log N}$ in the number of blocks.
			}
		\end{frame}

		\begin{frame}{\subsecname}
			
			\begin{block}{Client storage size}
				The position map is of size $N L = N \log N$ bits, which is of size $\BigO{N}$ blocks when the block size $\BigOmega{\log N}$ bits.

				The stash is at most $\BigO{\log N} \cdot \omega (1)$ blocks to obtain negligible failure probability.
				The recursive construction can achieve client storage of $\BigO{\log N} \cdot \omega (1)$.
			\end{block} 

			\note{
				Position map is the order of $N$ and the stash is the order of $\log N$ for negligible error probability.
				So, for the basic PathORAM the client storage usage is order fo $N$.
				However, it is possible to use recursive version of the ORAM, which I will talk about later, to lower the usage to the order of $\log N$.
			}
		\end{frame}

	\subsection{The algorithm}

		\newcommand{\algName}{\textsc{Access$(op, a, data^{*})$}}

%%% fragile frame
\begin{frame}[fragile]{Remap block}
		
	\lstinputlisting[
		firstline=1, 
		lastline=2,
		firstnumber=1,
		title=\algName%
	]{listings/algorithm.tex}
	
	\note{
		The client stash $S$ is initially empty. 
		The server buckets are initialized to contain randomized encryptions of the dummy blocks.
		The client's position map is filled with independent random numbers between 0 and $2^L - 1$.

		When the access occurs, the requested block is remapped.
	}

\end{frame}
%%% end fragile frame

%%% fragile frame
\begin{frame}[fragile]{Read path}
	
	\lstinputlisting[
		firstline=3, 
		lastline=5,
		firstnumber=3,
		title=\algName%
	]{listings/algorithm.tex}

	\note{
		Read the path $\mathcal{P}(x)$ containing block $a$.
	}

\end{frame}
%%% end fragile frame

%%% fragile frame
\begin{frame}[fragile]{Update block}
	
	\lstinputlisting[
		firstline=6,
		lastline=9,
		firstnumber=6,
		title=\algName%
	]{listings/algorithm.tex}

	\note{
		If the access is a \texttt{write}, update the data stored for block $a$.
	}

\end{frame}
%%% end fragile frame

%%% fragile frame
\begin{frame}[fragile]{Write path back}
		
	\lstinputlisting[
		firstline=10, 
		lastline=15,
		firstnumber=10,
		title=\algName%
	]{listings/algorithm.tex}

	\note{
		Write the path back and possibly include some additional blocks from the stash if they can be placed into the path.
		Buckets are greedily filled with blocks in the stash in the order of leaf to root, ensuring that blocks get pushed as deep down into the tree as possible.
		A block $a^\prime$ can be placed in the bucket at level $\ell$ only if the path $\mathcal{P}( \text{position}[a^\prime])$ to the leaf of block $a^\prime$ intersects the path accessed $\mathcal{P}(x)$ at level $\ell$.
		In other words, if $\mathcal{P}(x, \ell) = \mathcal{P}( \text{position}[a^\prime], \ell)$.
	}

\end{frame}
%%% end fragile frame

%%% fragile frame
\begin{frame}[fragile]{Return}
		
	\lstinputlisting[
		firstline=16,
		lastline=16,
		firstnumber=16,
		title=\algName%
	]{listings/algorithm.tex}

	\note{
		At the end, return the block.
	}

\end{frame}
%%% end fragile frame

\begin{frame}{Subroutines}
	
	\begin{block}{$\textsc{ReadBucket}(bucket)$}
		The client reads all $Z$ blocks (including any dummy blocks) from the $bucket$ stored on the server. 
		Blocks are decrypted as they are read.
	\end{block} 

	\begin{block}{$\textsc{WriteBucket}(bucket, blocks)$}
		The client writes the blocks $blocks$ into the specified $bucket$ on the server. 
		When writing, the client \emph{pads} blocks with dummy blocks to make it of size $Z$ --- note that this is important for security. 
		All blocks (including dummy blocks) are re-encrypted, using a randomized encryption scheme, as they are written.
	\end{block} 

	\note{
		There are two important subroutines in the algorithm.
		
		$\textsc{ReadBucket}(bucket)$ reads all $Z$ blocks --- remember, there are always exactly $Z$ blocks per bucket and decrypts them as it reads them.

		$\textsc{WriteBucket}(bucket, blocks)$ writes blocks in the bucket on the server.
		It pads blocks to make it $Z$ blocks total.
		Remember that all buckets should be filled to make them indistinguishable to adversary.
		Blocks are encrypted as they are written using randomized scheme --- every cipher text is different for the same plaintext.
	}
\end{frame}

		\begin{frame}{Complexity}
			
			\begin{block}{Computation}
				Client's computation is $\BigO{\log N} \cdot \omega (1)$ per data access. 
				We treat the server as a network storage device, so it only needs to do the computation necessary to retrieve and store $\BigO{\log N}$ blocks per data access.
			\end{block} 

			\note{
				Each access the client reads and writes the whole path, which is order of $\log N$ in size.
				It re-encrypts each block, so the total complexity is $\BigO{\log N} \cdot \omega (1)$.

				Server, on the other hand, does not perform encryption, so its complexity is $\BigO{\log N}$.
			}
		\end{frame}

%%% fragile frame
\begin{frame}[fragile]{Full algorithm}

	\begin{lrbox}{\mybox}%

		\lstinputlisting[
			firstline=1,
			lastline=16,
			title=\algName%
		]{listings/algorithm.tex}

	\end{lrbox}%
	
	\begin{center}

		\scalebox{0.75}{\usebox{\mybox}}

	\end{center}

	\note{
		Please, take a few moments and look at the whole algorithm.
		It is a great time now to ask any questions.
	}

\end{frame}
%%% end fragile frame

		\begin{frame}{Security analysis}
			
			\begin{gather*}
				\bm{p} = \left( \text{position}_M [a_M], \text{position}_{M-1} [a_{M-1}], \ldots , \text{position}_1 [a_1] \right) \\
				\Pr [ \bm{p} ] = \left( \frac{1}{2^L} \right)^M
			\end{gather*}

			\begin{itemize}
				\item 
					The sequence of encrypted paths is computationally indistinguishable from a random sequence of bit strings
				\item 
					$A(\vec{y})$ is computationally indistinguishable from a random sequence of bit strings
			\end{itemize}

			\note{
				Our definition of security requires that the access pattern is indistinguishable from random.
				Encrypted paths look random enough by the definition of secure encryption --- and we use randomized encryption since deterministic one does not even satisfy chosen plaintext attack security.
				The access pattern is random enough since the probability of a particular sequence is $\frac{1}{2^L}$ --- uniform in the number of blocks because each access the position table is re-randomized.
				For $M$ access, the probability is even smaller by the Bayes rule.
			}
		\end{frame}
